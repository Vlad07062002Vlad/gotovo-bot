import os
import io
import json
import base64
import sqlite3
import logging
import threading
from datetime import datetime
from http.server import BaseHTTPRequestHandler, HTTPServer
from typing import Optional, Tuple

from telegram import Update, BotCommand, InputFile
from telegram.ext import (
    Application, CommandHandler, MessageHandler, ContextTypes, filters
)

from openai import AsyncOpenAI

# ===== Ð›ÐžÐ“Ð˜ =====
logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    level=logging.INFO,
)
log = logging.getLogger("umnik")

# ===== ÐžÐšÐ Ð£Ð–Ð•ÐÐ˜Ð• =====
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PORT = int(os.getenv("PORT", "8080"))

if not TELEGRAM_TOKEN:
    raise SystemExit("TELEGRAM_TOKEN Ð½Ðµ Ð·Ð°Ð´Ð°Ð½. flyctl secrets set TELEGRAM_TOKEN=...")
if not OPENAI_API_KEY:
    raise SystemExit("OPENAI_API_KEY Ð½Ðµ Ð·Ð°Ð´Ð°Ð½. flyctl secrets set OPENAI_API_KEY=...")

# ===== OpenAI =====
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ===== Ð¥Ð ÐÐÐ˜Ð›Ð˜Ð©Ð• (SQLite Ð² Ñ„Ð°Ð¹Ð»Ðµ). ÐÐ° Fly Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ñ€Ð¸ÐºÑ€ÑƒÑ‚Ð¸Ñ‚ÑŒ volume /data =====
DB_PATH = os.getenv("DB_PATH", "data/umnik.db")
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

def db() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def init_db():
    conn = db()
    with conn:
        conn.execute("""
        CREATE TABLE IF NOT EXISTS users(
          uid INTEGER PRIMARY KEY,
          mode TEXT DEFAULT 'ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ',
          level TEXT DEFAULT '4',
          style TEXT DEFAULT 'ÐºÐ°Ðº ÑƒÑ‡ÐµÐ½Ð¸Ðº'
        )""")
        conn.execute("""
        CREATE TABLE IF NOT EXISTS history(
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          uid INTEGER,
          created_at TEXT,
          subject TEXT,
          mode TEXT,
          level TEXT,
          style TEXT,
          source TEXT,          -- 'text' | 'image' | 'voice'
          problem TEXT,
          solution TEXT,
          pdf BLOB
        )""")
    conn.close()

init_db()

# ===== Health-check HTTP (Ð´Ð»Ñ Fly) =====
class _Health(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b"ok")

def _run_health():
    HTTPServer(("0.0.0.0", PORT), _Health).serve_forever()

# ===== Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ =====
def get_or_create_user(uid: int) -> Tuple[str, str, str]:
    conn = db()
    row = conn.execute("SELECT mode, level, style FROM users WHERE uid=?", (uid,)).fetchone()
    if not row:
        with conn:
            conn.execute("INSERT INTO users(uid) VALUES(?)", (uid,))
        row = conn.execute("SELECT mode, level, style FROM users WHERE uid=?", (uid,)).fetchone()
    conn.close()
    return row["mode"], row["level"], row["style"]

def update_user(uid: int, **kwargs):
    allowed = {"mode", "level", "style"}
    sets, vals = [], []
    for k, v in kwargs.items():
        if k in allowed and v:
            sets.append(f"{k}=?")
            vals.append(v)
    if not sets:
        return
    vals.append(uid)
    conn = db()
    with conn:
        conn.execute(f"UPDATE users SET {', '.join(sets)} WHERE uid=?", vals)
    conn.close()

def add_history(uid: int, subject: str, mode: str, level: str, style: str,
                source: str, problem: str, solution: str, pdf_bytes: Optional[bytes]):
    conn = db()
    with conn:
        conn.execute("""
            INSERT INTO history(uid, created_at, subject, mode, level, style, source, problem, solution, pdf)
            VALUES(?,?,?,?,?,?,?,?,?,?)
        """, (
            uid, datetime.utcnow().isoformat(), subject, mode, level, style, source, problem, solution, pdf_bytes
        ))
    conn.close()

def fetch_history(uid: int, limit: int = 5):
    conn = db()
    rows = conn.execute("""
        SELECT id, created_at, subject, mode, level, style, source, problem, substr(solution,1,300)||'â€¦' as solution
        FROM history WHERE uid=? ORDER BY id DESC LIMIT ?
    """, (uid, limit)).fetchall()
    conn.close()
    return rows

def fetch_history_pdf(uid: int, item_id: int) -> Optional[bytes]:
    conn = db()
    row = conn.execute("SELECT pdf FROM history WHERE uid=? AND id=?", (uid, item_id)).fetchone()
    conn.close()
    return None if not row else row["pdf"]

def detect_subject(text: str) -> str:
    """ÐŸÑ€Ð¾ÑÑ‚ÐµÐ¹ÑˆÐ°Ñ ÑÐ²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ°, Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾Ñ‚Ð¾Ð¼ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚."""
    t = text.lower()
    if any(x in t for x in ["sin", "cos", "tg", "ÑƒÐ³Ð¾Ð»", "Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÑŒ", "ÑƒÑ€Ð°Ð²Ð½", "Ð´Ñ€Ð¾Ð±", "Ñ„ÑƒÐ½ÐºÑ†", "ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚"]):
        return "Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°"
    if any(x in t for x in ["Ð°Ñ‚Ð¾Ð¼", "Ñ€ÐµÐ°ÐºÑ†", "ÐºÐ¸ÑÐ»Ð¾Ñ‚Ð°", "Ð¾ÑÐ½Ð¾Ð²Ð°Ð½", "Ð²Ð°Ð»ÐµÐ½Ñ‚", "ÑÐ¾Ð»ÑŒ"]):
        return "Ñ…Ð¸Ð¼Ð¸Ñ"
    if any(x in t for x in ["ÑÐºÐ¾Ñ€Ð¾ÑÑ‚", "ÑÐ¸Ð»Ð°", "ÑÐ½ÐµÑ€Ð³", "Ð´Ð¶Ð¾ÑƒÐ»ÑŒ", "Ð½ÑŒÑŽÑ‚Ð¾Ð½", "Ñ‚ÐµÐ»Ð¾", "Ð´Ð²Ð¸Ð¶"]):
        return "Ñ„Ð¸Ð·Ð¸ÐºÐ°"
    if any(x in t for x in ["part of speech", "translate", "grammar", "essay"]) or "Ð°Ð½Ð³Ð»" in t:
        return "Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹"
    if any(x in t for x in ["Ð¿Ð¾Ð´Ð»ÐµÐ¶Ð°Ñ‰ÐµÐµ", "ÑÐºÐ°Ð·ÑƒÐµÐ¼Ð¾Ðµ", "Ð¼Ð¾Ñ€Ñ„Ð¾Ð»Ð¾Ð³", "Ð¾Ñ€Ñ„Ð¾Ð³Ñ€Ð°Ñ„", "Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†", "ÑÐ¾Ñ‡Ð¸Ð½ÐµÐ½Ð¸Ðµ"]):
        return "Ñ€ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº"
    if any(x in t for x in ["Ð¿Ñ‘Ñ‚Ñ€", "Ñ€ÐµÐ²Ð¾Ð»ÑŽÑ†", "Ð²ÐµÐ»Ð¸ÐºÐ°Ñ", "Ð²Ð¾Ð²", "Ð´Ñ€ÐµÐ²Ð½Ð¸Ð¹", "ÐºÐ½ÑÐ·ÑŒ", "Ð¸ÑÑ‚Ð¾Ñ€"]):
        return "Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ"
    if any(x in t for x in ["Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾", "Ð¿Ñ€Ð°Ð²Ð¾", "ÑÐºÐ¾Ð½Ð¾Ð¼", "Ð¿Ð¾Ð»Ð¸Ñ‚", "ÑÐ¾Ñ†Ð¸Ð¾Ð»Ð¾Ð³"]):
        return "Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ"
    return "Ð¾Ð±Ñ‰Ð¸Ð¹"

# ===== OpenAI Ð²Ñ‹Ð·Ð¾Ð²Ñ‹ =====
async def openai_ocr_and_solve(image_b64: str, mode: str, level: str, style: str) -> Tuple[str, str]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (subject, solution_md)
    """
    system = (
        "Ð¢Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑˆÐºÐ¾Ð»ÑŒÐ½Ð¸ÐºÐ¾Ð² (Ð¤Ð“ÐžÐ¡, 5â€“11 ÐºÐ»Ð°ÑÑÑ‹). "
        "Ð’ÑÐµÐ³Ð´Ð° Ð¾Ð±ÑŠÑÑÐ½ÑÐ¹ Ð¿Ð¾ ÑˆÐ°Ð³Ð°Ð¼ Ð¸ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼Ð¸ Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸ÑÐ¼Ð¸, Ð±ÐµÐ· Ñ„Ð¾Ñ€Ð¼ÑƒÐ» Ñ€Ð°Ð´Ð¸ Ñ„Ð¾Ñ€Ð¼ÑƒÐ». "
        "Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑˆÐ¸ ÑƒÑÐ»Ð¾Ð²Ð¸Ðµ (ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ â€” Ð¸ÑÐ¿Ñ€Ð°Ð²ÑŒ OCR-Ð¾ÑˆÐ¸Ð±ÐºÐ¸), Ð·Ð°Ñ‚ÐµÐ¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ, Ð·Ð°Ñ‚ÐµÐ¼ "
        "Ð±Ð»Ð¾Ðº 'ÐšÑ€Ð°Ñ‚ÐºÐ¾' Ð½Ð° 2â€“3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ. Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸ 1â€“2 Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¾Ñ‡Ð½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°."
    )
    mode_hint = {
        "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ": "Ð—Ð°Ð´Ð°Ð²Ð°Ð¹ 2â€“3 Ð½Ð°Ð²Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° Ð¿Ð¾ Ñ…Ð¾Ð´Ñƒ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ, Ð½Ð¾ Ð²ÑÑ‘ Ð¶Ðµ Ð´Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ.",
        "ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°": "Ð”Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ¸ Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑˆÐ°Ð³Ð¸ Ð±ÐµÐ· Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°, Ð½Ð¾ Ñ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼.",
        "Ð“Ð¾Ñ‚Ð¾Ð²Ð¾": "Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ."
    }.get(mode, "Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ.")
    user = [
        {"type": "text", "text": f"Ð ÐµÐ¶Ð¸Ð¼: {mode}. Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: {level}. Ð¡Ñ‚Ð¸Ð»ÑŒ: {style}. {mode_hint}\n"
                                 f"1) Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ Ñ Ñ„Ð¾Ñ‚Ð¾.\n"
                                 f"2) ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚.\n"
                                 f"3) Ð ÐµÑˆÐ¸ Ð¸Ð»Ð¸ Ð¾Ð±ÑŠÑÑÐ½Ð¸ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾.\n"
                                 f"4) Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð²Ñ‹Ð´Ð°Ð¹ Ð¼ÐµÑ‚ÐºÑƒ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ: [ÐŸÐ Ð•Ð”ÐœÐ•Ð¢: ...]."},
        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
    ]

    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.2,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ]
    )
    out = resp.choices[0].message.content.strip()
    # Ð’Ñ‹Ð´ÐµÑ€Ð½ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚
    subj = "Ð¾Ð±Ñ‰Ð¸Ð¹"
    marker = "[ÐŸÐ Ð•Ð”ÐœÐ•Ð¢:"
    if marker in out:
        tail = out.split(marker, 1)[-1]
        subj = tail.split("]", 1)[0].strip().lower()
    return subj, out

async def openai_solve_text(problem: str, mode: str, level: str, style: str) -> str:
    system = (
        "Ð¢Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑˆÐºÐ¾Ð»ÑŒÐ½Ð¸ÐºÐ¾Ð² (Ð¤Ð“ÐžÐ¡, 5â€“11 ÐºÐ»Ð°ÑÑÑ‹). "
        "ÐžÐ±ÑŠÑÑÐ½ÑÐ¹ Ð¿Ð¾ ÑˆÐ°Ð³Ð°Ð¼, Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ð¼Ð¸ ÑÐ»Ð¾Ð²Ð°Ð¼Ð¸, Ñ Ð±Ñ‹Ñ‚Ð¾Ð²Ñ‹Ð¼Ð¸ Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸ÑÐ¼Ð¸. "
        "Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°: Ð£ÑÐ»Ð¾Ð²Ð¸Ðµ (ÐºÑ€Ð°Ñ‚ÐºÐ¾) â†’ Ð ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑˆÐ°Ð³Ð°Ð¼ â†’ ÐšÑ€Ð°Ñ‚ÐºÐ¾ (2â€“3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ) â†’ "
        "ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¾Ñ‡Ð½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ (1â€“2)."
    )
    mode_hint = {
        "ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ": "Ð—Ð°Ð´Ð°Ð²Ð°Ð¹ Ð¿Ð¾ Ñ…Ð¾Ð´Ñƒ 2â€“3 Ð½Ð°Ð²Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°, Ð½Ð¾ Ð´Ð°Ð»ÐµÐµ Ð¿Ð¾ÐºÐ°Ð¶Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ñ…Ð¾Ð´ Ð¼Ñ‹ÑÐ»ÐµÐ¹.",
        "ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°": "Ð”Ð°Ð¹ 3â€“5 Ð¿Ð¾Ð´ÑÐºÐ°Ð·Ð¾Ðº Ð¸ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð±ÐµÐ· Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°.",
        "Ð“Ð¾Ñ‚Ð¾Ð²Ð¾": "Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ."
    }.get(mode, "Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ.")
    user = (
        f"Ð ÐµÐ¶Ð¸Ð¼: {mode}. Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: {level}. Ð¡Ñ‚Ð¸Ð»ÑŒ: {style}. {mode_hint}\n"
        f"Ð—Ð°Ð´Ð°Ð½Ð¸Ðµ:\n{problem}"
    )
    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.2,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user}
        ]
    )
    return resp.choices[0].message.content.strip()

async def openai_transcribe(file_bytes: bytes, mime: str) -> str:
    # Whisper-1 ÑÑ‚Ð°Ð±Ð¸Ð»ÐµÐ½ Ð´Ð»Ñ STT
    return (await client.audio.transcriptions.create(
        model="whisper-1",
        file=("audio", file_bytes, mime),
        response_format="text",
        temperature=0.0,
        language="ru"
    ))

async def openai_tts(text: str) -> bytes:
    # ÐžÐ·Ð²ÑƒÑ‡ÐºÐ° Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ
    speech = await client.audio.speech.create(
        model="tts-1",
        voice="alloy",
        input=text
    )
    return speech.read()

# ===== PDF ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ =====
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import cm
from reportlab.pdfgen import canvas

def make_pdf(title: str, problem: str, solution: str) -> bytes:
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=A4)
    width, height = A4
    x, y = 2*cm, height-2*cm

    def txt(s: str, size=11, leading=14):
        nonlocal y
        c.setFont("Helvetica", size)
        for line in s.splitlines():
            for sub in _wrap(line, 90):
                c.drawString(x, y, sub)
                y -= leading
                if y < 2*cm:
                    c.showPage(); y = height-2*cm; c.setFont("Helvetica", size)

    def _wrap(s, n):
        return [s[i:i+n] for i in range(0, len(s), n)]

    c.setTitle(title)
    c.setFont("Helvetica-Bold", 14); c.drawString(x, y, title); y -= 22
    c.setFont("Helvetica-Bold", 12); c.drawString(x, y, "Ð£ÑÐ»Ð¾Ð²Ð¸Ðµ:"); y -= 18
    txt(problem, 11, 15); y -= 8
    c.setFont("Helvetica-Bold", 12); c.drawString(x, y, "Ð ÐµÑˆÐµÐ½Ð¸Ðµ:"); y -= 18
    txt(solution, 11, 15)
    c.showPage(); c.save()
    return buf.getvalue()

# ===== ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ =====
async def set_commands(app: Application):
    await app.bot.set_my_commands([
        BotCommand("start", "ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ"),
        BotCommand("help", "ÐšÐ°Ðº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ"),
        BotCommand("mode", "Ð ÐµÐ¶Ð¸Ð¼: ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ/ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°/Ð“Ð¾Ñ‚Ð¾Ð²Ð¾"),
        BotCommand("level", "Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: 3/4/5"),
        BotCommand("style", "Ð¡Ñ‚Ð¸Ð»ÑŒ: ÐºÐ°Ðº ÑƒÑ‡ÐµÐ½Ð¸Ðº/ÑƒÐ³Ð»ÑƒÐ±Ð»Ñ‘Ð½Ð½Ð¾"),
        BotCommand("solve", "Ð ÐµÑˆÐ¸Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ"),
        BotCommand("essay", "Ð¡Ð¾Ñ‡Ð¸Ð½ÐµÐ½Ð¸Ðµ/ÑÑÑÐµ"),
        BotCommand("doc", "Ð”Ð¾ÐºÐ»Ð°Ð´ (Ñ‚ÐµÐ¼Ð°)"),
        BotCommand("pres", "ÐŸÑ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ (ÐºÑ€Ð°Ñ‚ÐºÐ¾)"),
        BotCommand("history", "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ"),
        BotCommand("saylast", "ÐžÐ·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ"),
    ])

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    mode, level, style = get_or_create_user(uid)
    await update.message.reply_text(
        "ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¯ Â«Ð£Ð¼Ð½Ð¸ÐºÂ» â€” Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ Ñ Ð”Ð— Ñ‚Ð°Ðº, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ‚Ñ‹ Ð¿Ð¾Ð½ÑÐ».\n\n"
        "âž• Ð¡Ñ„Ð¾Ñ‚ÐºÐ°Ð¹ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ â€” Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ Ð¸ Ð¾Ð±ÑŠÑÑÐ½ÑŽ.\n"
        "ðŸŽ™ ÐœÐ¾Ð¶ÐµÑˆÑŒ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼.\n"
        "âš™ /mode /level /style â€” Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸.\n"
        "ðŸ—‚ /history â€” Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ.\n\n"
        f"Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸: Ñ€ÐµÐ¶Ð¸Ð¼ *{mode}*, ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ *{level}*, ÑÑ‚Ð¸Ð»ÑŒ *{style}*.",
        parse_mode="Markdown"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ÐšÐ°Ðº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ:\n"
        "1) Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ„Ð¾Ñ‚Ð¾ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ ÑÑŽÐ´Ð°.\n"
        "2) Ð˜Ð»Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚ /solve Ð¢Ð•ÐšÐ¡Ð¢.\n"
        "3) /mode ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ|ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°|Ð“Ð¾Ñ‚Ð¾Ð²Ð¾ â€” Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸.\n"
        "4) /level 3|4|5 â€” Ð³Ð»ÑƒÐ±Ð¸Ð½Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°.\n"
        "5) /style Â«ÐºÐ°Ðº ÑƒÑ‡ÐµÐ½Ð¸ÐºÂ»|Â«ÑƒÐ³Ð»ÑƒÐ±Ð»Ñ‘Ð½Ð½Ð¾Â» â€” ÑÑ‚Ð¸Ð»ÑŒ.\n"
        "6) Ð“Ð¾Ð»Ð¾Ñ â€” Ð¿Ñ€Ð¾Ð´Ð¸ÐºÑ‚ÑƒÐ¹ Ð·Ð°Ð´Ð°Ð½Ð¸Ðµ (Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÑŽ)."
    )

async def mode_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    if context.args:
        val = " ".join(context.args).strip().capitalize()
        if val in ["ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ", "ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°", "Ð“Ð¾Ñ‚Ð¾Ð²Ð¾"]:
            update_user(uid, mode=val)
            await update.message.reply_text(f"Ð ÐµÐ¶Ð¸Ð¼ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½: {val}")
            return
    await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ Ð¾Ð´Ð¸Ð½ Ð¸Ð· Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð²: ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ / ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ° / Ð“Ð¾Ñ‚Ð¾Ð²Ð¾")

async def level_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    if context.args and context.args[0] in ["3", "4", "5"]:
        update_user(uid, level=context.args[0])
        await update.message.reply_text(f"Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½: {context.args[0]}")
    else:
        await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ: 3 / 4 / 5")

async def style_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    if context.args:
        val = " ".join(context.args).strip().lower()
        if val in ["ÐºÐ°Ðº ÑƒÑ‡ÐµÐ½Ð¸Ðº", "ÑƒÐ³Ð»ÑƒÐ±Ð»Ñ‘Ð½Ð½Ð¾"]:
            update_user(uid, style=val)
            await update.message.reply_text(f"Ð¡Ñ‚Ð¸Ð»ÑŒ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½: {val}")
            return
    await update.message.reply_text('Ð£ÐºÐ°Ð¶Ð¸ ÑÑ‚Ð¸Ð»ÑŒ: "ÐºÐ°Ðº ÑƒÑ‡ÐµÐ½Ð¸Ðº" Ð¸Ð»Ð¸ "ÑƒÐ³Ð»ÑƒÐ±Ð»Ñ‘Ð½Ð½Ð¾"')

async def solve_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    mode, level, style = get_or_create_user(uid)
    problem = " ".join(context.args).strip()
    if not problem:
        await update.message.reply_text("Ð”Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ: /solve Ð¢Ð•ÐšÐ¡Ð¢_Ð—ÐÐ”ÐÐÐ˜Ð¯")
        return
    await update.message.chat.send_action("typing")
    try:
        subject = detect_subject(problem)
        solution = await openai_solve_text(problem, mode, level, style)
        pdf = make_pdf(f"Ð£Ð¼Ð½Ð¸Ðº â€” {subject}", problem, solution)
        add_history(uid, subject, mode, level, style, "text", problem, solution, pdf)
        await update.message.reply_text(solution[:4000])
        await update.message.reply_document(
            document=InputFile(io.BytesIO(pdf), filename="solution.pdf"),
            caption="Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² PDF"
        )
    except Exception as e:
        log.exception("solve_cmd")
        await update.message.reply_text(f"ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ Ñ€ÐµÑˆÐ¸Ñ‚ÑŒ: {e}")

async def essay_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    topic = " ".join(context.args).strip()
    if not topic:
        await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ Ñ‚ÐµÐ¼Ñƒ: /essay Ð¢Ð•ÐœÐ")
        return
    await update.message.chat.send_action("typing")
    try:
        resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.7,
            messages=[
                {"role": "system", "content": "ÐŸÐ¸ÑˆÐ¸ ÑÐ¾Ñ‡Ð¸Ð½ÐµÐ½Ð¸Ðµ 180â€“220 ÑÐ»Ð¾Ð², Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸, Ð±ÐµÐ· Ð¿Ð»Ð°Ð³Ð¸Ð°Ñ‚Ð°, Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ð¾ Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ð¾."},
                {"role": "user", "content": f"Ð¢ÐµÐ¼Ð°: {topic}"}
            ]
        )
        out = resp.choices[0].message.content.strip()
        await update.message.reply_text(out[:4000])
    except Exception as e:
        log.exception("essay")
        await update.message.reply_text(f"Ð¡Ð±Ð¾Ð¹ Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {e}")

async def doc_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    topic = " ".join(context.args).strip()
    if not topic:
        await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ Ñ‚ÐµÐ¼Ñƒ: /doc Ð¢Ð•ÐœÐ")
        return
    await update.message.chat.send_action("typing")
    try:
        resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.5,
            messages=[
                {"role": "system", "content": "Ð¡Ð´ÐµÐ»Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð´Ð¾ÐºÐ»Ð°Ð´ 350â€“500 ÑÐ»Ð¾Ð², Ñ Ð¿Ð¾Ð´Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼Ð¸ Ð¸ Ñ‚ÐµÐ·Ð¸ÑÐ°Ð¼Ð¸, Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸."},
                {"role": "user", "content": f"Ð¢ÐµÐ¼Ð° Ð´Ð¾ÐºÐ»Ð°Ð´Ð°: {topic}"}
            ]
        )
        out = resp.choices[0].message.content.strip()
        pdf = make_pdf(f"Ð”Ð¾ÐºÐ»Ð°Ð´ â€” {topic}", topic, out)
        await update.message.reply_document(
            document=InputFile(io.BytesIO(pdf), filename="report.pdf"),
            caption="Ð”Ð¾ÐºÐ»Ð°Ð´ Ð² PDF"
        )
    except Exception as e:
        log.exception("doc")
        await update.message.reply_text(f"Ð¡Ð±Ð¾Ð¹ Ð¿Ñ€Ð¸ Ð´Ð¾ÐºÐ»Ð°Ð´Ðµ: {e}")

async def pres_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    topic = " ".join(context.args).strip()
    if not topic:
        await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ Ñ‚ÐµÐ¼Ñƒ: /pres Ð¢Ð•ÐœÐ")
        return
    await update.message.chat.send_action("typing")
    try:
        resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.5,
            messages=[
                {"role": "system", "content": "Ð¡Ð´ÐµÐ»Ð°Ð¹ 6â€“8 ÑÐ»Ð°Ð¹Ð´Ð¾Ð²-Ð¿Ñ€Ð¾ÑÐ»Ð°Ð¹Ð´Ð¾Ð²ÐºÑƒ Ð² Ð²Ð¸Ð´Ðµ Markdown: #Title + bullets."},
                {"role": "user", "content": f"Ð¢ÐµÐ¼Ð° Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸: {topic}"}
            ]
        )
        md = resp.choices[0].message.content.strip()
        pdf = make_pdf(f"ÐŸÑ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ â€” {topic}", topic, md)
        await update.message.reply_document(
            document=InputFile(io.BytesIO(pdf), filename="presentation.pdf"),
            caption="ÐŸÑ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ (PDF-Ð²ÐµÑ€ÑÐ¸Ñ)"
        )
    except Exception as e:
        log.exception("pres")
        await update.message.reply_text(f"Ð¡Ð±Ð¾Ð¹ Ð¿Ñ€Ð¸ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸: {e}")

async def on_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    mode, level, style = get_or_create_user(uid)
    await update.message.chat.send_action("typing")
    try:
        photo = update.message.photo[-1]
        f = await context.bot.get_file(photo.file_id)
        bio = io.BytesIO()
        await f.download_to_memory(out=bio)
        b64 = base64.b64encode(bio.getvalue()).decode("ascii")

        subject, solution = await openai_ocr_and_solve(b64, mode, level, style)
        # OCR-Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð´Ð»Ñ PDF (Ð¿Ñ€Ð¾ÑÐ¸Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾)
        p_resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.0,
            messages=[
                {"role": "system", "content": "Ð˜Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð²Ñ‹Ð´ÐµÐ»Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ (2â€“4 ÑÑ‚Ñ€Ð¾ÐºÐ¸), Ð±ÐµÐ· Ñ€ÐµÑˆÐµÐ½Ð¸Ñ."},
                {"role": "user", "content": solution}
            ]
        )
        problem = p_resp.choices[0].message.content.strip()
        pdf = make_pdf(f"Ð£Ð¼Ð½Ð¸Ðº â€” {subject}", problem, solution)
        add_history(uid, subject, mode, level, style, "image", problem, solution, pdf)

        await update.message.reply_text(solution[:4000])
        await update.message.reply_document(
            document=InputFile(io.BytesIO(pdf), filename="solution.pdf"),
            caption="Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² PDF"
        )
    except Exception as e:
        log.exception("photo")
        await update.message.reply_text(f"ÐÐµ ÑÐ¼Ð¾Ð³ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾: {e}")

async def on_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    mode, level, style = get_or_create_user(uid)
    await update.message.chat.send_action("typing")
    try:
        voice = update.message.voice or update.message.audio
        if not voice:
            return
        f = await context.bot.get_file(voice.file_id)
        bio = io.BytesIO()
        await f.download_to_memory(out=bio)
        # Telegram Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°ÐµÑ‚ OGG/OPUS; Ð´Ð»Ñ whisper-1 Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾.
        transcript = await openai_transcribe(bio.getvalue(), mime="audio/ogg")
        subject = detect_subject(transcript)
        solution = await openai_solve_text(transcript, mode, level, style)
        pdf = make_pdf(f"Ð£Ð¼Ð½Ð¸Ðº â€” {subject}", transcript, solution)
        add_history(uid, subject, mode, level, style, "voice", transcript, solution, pdf)
        await update.message.reply_text(solution[:4000])
    except Exception as e:
        log.exception("voice")
        await update.message.reply_text(f"Ð¡ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼ Ð½Ðµ Ð²Ñ‹ÑˆÐ»Ð¾: {e}")

async def history_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    rows = fetch_history(uid, limit=5)
    if not rows:
        await update.message.reply_text("Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿ÑƒÑÑ‚Ð°. ÐŸÑ€Ð¸ÑˆÐ»Ð¸ Ñ„Ð¾Ñ‚Ð¾ Ð¸Ð»Ð¸ /solve Ñ‚ÐµÐºÑÑ‚.")
        return
    text = ["ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ:"]
    for r in rows:
        text.append(
            f"#{r['id']} â€¢ {r['created_at'][:19]} â€¢ {r['subject']} â€¢ {r['mode']}/{r['level']}/{r['style']} â€¢ "
            f"{r['source']}\nâ€” {r['problem'][:80].replace(os.linesep,' ')}"
        )
    await update.message.reply_text("\n\n".join(text[:4096]))

async def saylast_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    conn = db()
    row = conn.execute(
        "SELECT id, solution FROM history WHERE uid=? ORDER BY id DESC LIMIT 1", (uid,)
    ).fetchone()
    conn.close()
    if not row:
        await update.message.reply_text("ÐŸÐ¾ÐºÐ° Ð½ÐµÑ‚ Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð² Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸.")
        return
    try:
        audio_bytes = await openai_tts(row["solution"][:2000])
        await update.message.reply_voice(voice=InputFile(io.BytesIO(audio_bytes), filename="explain.ogg"))
    except Exception as e:
        log.exception("tts")
        await update.message.reply_text(f"ÐÐµ ÑÐ¼Ð¾Ð³ Ð¾Ð·Ð²ÑƒÑ‡Ð¸Ñ‚ÑŒ: {e}")

async def exportpdf_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    if not context.args:
        await update.message.reply_text("Ð£ÐºÐ°Ð¶Ð¸ ID Ð¸Ð· /history: /exportpdf 12")
        return
    try:
        item_id = int(context.args[0])
    except ValueError:
        await update.message.reply_text("ID Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾Ð¼. ÐŸÑ€Ð¸Ð¼ÐµÑ€: /exportpdf 12")
        return
    pdf = fetch_history_pdf(uid, item_id)
    if not pdf:
        await update.message.reply_text("ÐÐµ Ð½Ð°ÑˆÑ‘Ð» PDF Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ ID.")
        return
    await update.message.reply_document(
        document=InputFile(io.BytesIO(pdf), filename=f"solution_{item_id}.pdf"),
        caption="Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¸Ð· Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸"
    )

def main():
    threading.Thread(target=_run_health, daemon=True).start()

    app = Application.builder().token(TELEGRAM_TOKEN).build()
    app.post_init = set_commands

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("mode", mode_cmd))
    app.add_handler(CommandHandler("level", level_cmd))
    app.add_handler(CommandHandler("style", style_cmd))
    app.add_handler(CommandHandler("solve", solve_cmd))
    app.add_handler(CommandHandler("essay", essay_cmd))
    app.add_handler(CommandHandler("doc", doc_cmd))
    app.add_handler(CommandHandler("pres", pres_cmd))
    app.add_handler(CommandHandler("history", history_cmd))
    app.add_handler(CommandHandler("saylast", saylast_cmd))
    app.add_handler(CommandHandler("exportpdf", exportpdf_cmd))

    app.add_handler(MessageHandler(filters.PHOTO, on_photo))
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, on_voice))

    log.info("Umnik bot is runningâ€¦")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
